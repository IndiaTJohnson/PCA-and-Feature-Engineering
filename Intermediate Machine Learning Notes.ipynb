{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40797eb2-fe9e-47aa-81de-071a70a65212",
   "metadata": {},
   "source": [
    "# PCA for Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd2547d-53c2-437b-99ed-af646e473a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler,OrdinalEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import set_config\n",
    "set_config(transform_output='pandas')\n",
    "pd.set_option('display.max_columns',100)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc90f38-9fbe-4da0-9e7b-339a3df08403",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Data/modified-Data_Cortex_Nuclear.csv\")\n",
    "# Dropping unique IDs\n",
    "df = df.drop(columns=['MouseID'])\n",
    "df.info()\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d088fa97-7227-47c4-a922-7d70031eb732",
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_targets = ['Type of Mouse',\"Treatment\",'Training','class',]\n",
    "for col in possible_targets:\n",
    "    print(f'\\n- {col}:')\n",
    "    print(df[col].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9425e056-f09c-4a77-b268-178e4df2a370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and y\n",
    "target = \"Training\"\n",
    "X = df.drop(columns = possible_targets)\n",
    "y = df[target]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a780279b-3cc1-4fb2-98cb-6659a76aff76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import missingno as msno\n",
    "msno.matrix(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b265f5-19fc-41ea-bae8-229bed7d4abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in nulls with 0 and verify all nulls are addressed\n",
    "X = X.fillna(0)\n",
    "X.isna().sum().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e22cdad-5ab5-46ea-9a1b-ebf84f477143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Standard Scaler\n",
    "scaler = StandardScaler()\n",
    "# Fit & transform data.\n",
    "scaled_df = scaler.fit_transform(X)\n",
    "scaled_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d42357c-ba47-4aa1-b471-ebcf17540fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the correlation matrix and plotting\n",
    "corr = scaled_df.corr()\n",
    "sns.heatmap(corr, cmap='coolwarm');\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1771113-14ce-4328-93c1-279abf517c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a scatter_matrix with pandas\n",
    "pd.plotting.scatter_matrix(scaled_df, figsize=(40,40));\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea599ff5-ba25-42de-a656-1c86637b5be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly select features to plot\n",
    "np.random.seed(42)\n",
    "random_features = np.random.choice(scaled_df.columns,3)\n",
    "# plot thee randomly selected features\n",
    "sns.pairplot(scaled_df,  vars=random_features);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d2143e-6f0c-46f7-a066-b12d251ccada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate scaled features with target\n",
    "plot_df = pd.concat([scaled_df, df[target]], axis=1)\n",
    "# Plot with color coding based on target\n",
    "g = sns.pairplot(data=plot_df,  vars=random_features, hue='Training')\n",
    "g.fig.suptitle('Visualizing Raw Features - Colored by Training', y=1.01);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979b3afc-4662-44ca-b6ea-4c45b4da72b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate PCA to make 3 principal components\n",
    "pca = PCA(n_components=3)\n",
    "# Create and define the principal components\n",
    "principal_components = pca.fit_transform(scaled_df)\n",
    "# Preview the results\n",
    "principal_components.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb9a1d1-9a34-4168-91ea-15e10eb1c259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance explained by each PC\n",
    "pca.explained_variance_ratio_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef20216-ecc9-40cc-9cc1-3cfa96548173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum of variance explained by 3 principal components\n",
    "pca.explained_variance_ratio_.sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd6e7f2-d856-422b-b0f3-5f8b83c1a180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate principal components with target\n",
    "plot_df_pca = pd.concat([principal_components, df[target]], axis=1)\n",
    "# Plot with color coding based on target\n",
    "g_pca = sns.pairplot(data=plot_df_pca,  vars=principal_components.columns, hue='Training')\n",
    "g_pca.fig.suptitle('Visualizing First 3 PCs - Colored by Training', y=1.01);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befa509b-736c-411b-a76b-3df6b7d0e2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "# Make a 3d scatter plot with a PC on each axis and color by the target\n",
    "fig = px.scatter_3d(plot_df_pca, x='pca0',y='pca1',z='pca2', width=800, height=600, color = \"Training\")\n",
    "fig\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f531b0-c1f2-49b4-8fee-16d97e632e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_scatter3d(fig):\n",
    "    fig.update_traces({'marker':{'size':3}})\n",
    "    fig.show(config={'scrollZoom':False})\n",
    "update_scatter3d(fig)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b67aa1-64b8-494c-80b9-d4e6e5ae462c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See avaialbe templates\n",
    "pio.templates\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1fde35-76cc-4355-921e-98e28f1ff8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a 3d scatter plot with a PC on each axis and color by the target\n",
    "# Change template style to plotly_dark\n",
    "fig = px.scatter_3d(plot_df_pca, x='pca0',y='pca1',z='pca2', width=800, height=600, color = \"Training\", template = 'plotly_dark')\n",
    "update_scatter3d(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6936c17-c975-4721-95de-f551f4344fdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ca79df9-42d7-4feb-9881-27162011368b",
   "metadata": {},
   "source": [
    "# PCA to Speed up Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38ac285-9759-4a91-862e-5edb38478621",
   "metadata": {},
   "source": [
    "## PCA for Supervised Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0541706c-5d99-48de-8dca-e1144222db18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pd.set_option('display.max_columns',200)\n",
    "pd.set_option(\"display.max_info_rows\", 800)\n",
    "pd.set_option('display.max_info_columns',800)\n",
    "\n",
    "from sklearn import set_config\n",
    "set_config(transform_output='pandas')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300bb4f7-ba25-4d6f-aeb3-295b5ea97fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def classification_metrics(y_true, y_pred, label='',\n",
    "                           output_dict=False, figsize=(8,4),\n",
    "                           normalize='true', cmap='Blues',\n",
    "                           colorbar=False):\n",
    "    # Get the classification report\n",
    "    report = classification_report(y_true, y_pred)\n",
    "    ## Print header and report\n",
    "    header = \"-\"*70\n",
    "    print(header, f\" Classification Metrics: {label}\", header, sep='\\n')\n",
    "    print(report)\n",
    "    ## CONFUSION MATRICES SUBPLOTS\n",
    "    fig, axes = plt.subplots(ncols=2, figsize=figsize)\n",
    "    # create a confusion matrix  of raw counts\n",
    "    ConfusionMatrixDisplay.from_predictions(y_true, y_pred,\n",
    "                normalize=None, cmap='gist_gray', colorbar=colorbar,\n",
    "                ax = axes[0],);\n",
    "    axes[0].set_title(\"Raw Counts\")\n",
    "    # create a confusion matrix with the test data\n",
    "    ConfusionMatrixDisplay.from_predictions(y_true, y_pred,\n",
    "                normalize=normalize, cmap=cmap, colorbar=colorbar,\n",
    "                ax = axes[1]);\n",
    "    axes[1].set_title(\"Normalized Confusion Matrix\")\n",
    "    # Adjust layout and show figure\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    # Return dictionary of classification_report\n",
    "    if output_dict==True:\n",
    "        report_dict = classification_report(y_true, y_pred, output_dict=True)\n",
    "        return report_dict\n",
    "\n",
    "\n",
    "def evaluate_classification(model, X_train, y_train, X_test, y_test,\n",
    "                         figsize=(6,4), normalize='true', output_dict = False,\n",
    "                            cmap_train='Blues', cmap_test=\"Reds\",colorbar=False):\n",
    "    # Get predictions for training data\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    # Call the helper function to obtain regression metrics for training data\n",
    "    results_train = classification_metrics(y_train, y_train_pred, #verbose = verbose,\n",
    "                                     output_dict=True, figsize=figsize,\n",
    "                                         colorbar=colorbar, cmap=cmap_train,\n",
    "                                     label='Training Data')\n",
    "    print()\n",
    "    # Get predictions for test data\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    # Call the helper function to obtain regression metrics for test data\n",
    "    results_test = classification_metrics(y_test, y_test_pred, #verbose = verbose,\n",
    "                                  output_dict=True,figsize=figsize,\n",
    "                                         colorbar=colorbar, cmap=cmap_test,\n",
    "                                    label='Test Data' )\n",
    "    if output_dict == True:\n",
    "        # Store results in a dataframe if ouput_frame is True\n",
    "        results_dict = {'train':results_train,\n",
    "                    'test': results_test}\n",
    "        return results_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893ff6b3-c173-4ad3-ac2e-0aee885c32cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Data\n",
    "df = pd.read_csv('Data/pd_speech_features.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79a08d4-3812-4215-9da5-01b85142587f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048adb79-3d68-40c2-b035-7431e36112b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689762bc-7f34-406e-9a1c-98e4fd56506d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target and cols to drop\n",
    "target_col = 'class'\n",
    "drop_cols = ['id']\n",
    "# Define X and y\n",
    "y = df[target_col].copy()\n",
    "X = df.drop(columns=[target_col,*drop_cols]).copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f127df-1b1d-4249-82d7-3b11d6f7c5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y, random_state=321)\n",
    "X_train.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c765b383-f06f-493b-b6f2-9308cb726de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Standard Scaler\n",
    "scaler = StandardScaler()\n",
    "# Fit & transform data.\n",
    "X_train_tf = scaler.fit_transform(X_train)\n",
    "X_test_tf = scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249b41f8-3458-474d-800a-ff467c2bb076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for class balance of target\n",
    "y_train.value_counts(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2947769-e41a-4d40-8657-6149c61c32a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE,SMOTENC\n",
    "smote = SMOTE()\n",
    "X_train_sm, y_train_sm = smote.fit_resample(X_train_tf, y_train)\n",
    "y_train_sm.value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa6bd86-40e2-422d-bd77-10b3da2d401f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import datetime library\n",
    "import datetime as dt\n",
    "\n",
    "# Record the start time\n",
    "start = dt.datetime.now()\n",
    "\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "clf.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "# Record the end time and calc duration\n",
    "end = dt.datetime.now()\n",
    "dur_baseline = end-start\n",
    "\n",
    "evaluate_classification(clf, X_train_sm,y_train_sm, X_test_tf, y_test)\n",
    "print(f'Training time was: {dur_baseline}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a790441f-0e9f-448a-ab10-ed6094a0f80a",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaadb934-8a60-43f5-93b8-7f3231d3d5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate & fit data using PCA\n",
    "pca = PCA(n_components=3)\n",
    "X_train_pca = pca.fit_transform(X_train_sm)\n",
    "X_test_pca = pca.transform(X_test_tf)\n",
    "X_train_pca.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098b02f1-bb78-46d5-9a66-500c57c6b0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record the start time\n",
    "start = dt.datetime.now()\n",
    "\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_train_pca, y_train_sm)\n",
    "\n",
    "# Record the end time and calc duration\n",
    "end = dt.datetime.now()\n",
    "dur_pca = end-start\n",
    "\n",
    "evaluate_classification(clf, X_train_pca,y_train_sm, X_test_pca, y_test)\n",
    "print(f'Training time was: {dur_pca}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9108c2-229c-4141-b891-4e61eb0e1f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare speeds before and after PCA\n",
    "compare_speed = dur_baseline/dur_pca\n",
    "print(f\"Using PCs was {compare_speed:.2f} times faster!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb38545-34a3-434b-b9fc-2d352fc7d3f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04e48a1-2336-425f-8d4a-9ad3e42376e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and fit PCA\n",
    "pca = PCA()\n",
    "pca.fit(X_train_sm, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb6d093-9074-4e39-8677-8956e4173d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine how much variance is explained by each PC\n",
    "explained = pd.Series(pca.explained_variance_ratio_, name='Explained Variance Ratio')\n",
    "explained\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a48fb60-13cb-4514-b603-2a248fe71716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the cumulative sum of the percentage of explained variance for each component and those before it.\n",
    "ax = explained.cumsum().plot(marker='.')\n",
    "# add a line to mark .9 (or 90%) variance explained\n",
    "ax.axhline(.9, color='k');\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e144d01-4bba-4ff0-a0b4-d044c4bf77a9",
   "metadata": {},
   "source": [
    "### Specifying the Explained Variance\r\n",
    "Rather than specifying the number of components to return, an alternate method is to specify the minimum proportion of explained variance you are willing to accept. PCA will automatically reduce the number of components just enough to meet your specification.\r\n",
    "\r\n",
    "To specify the proportion of variance, give the n_components argument a float between 0 and 1, and it will return the number of components required to explain the given variance.\r\n",
    "\r\n",
    "The code below is an example of how to ensure that enough components are returned to explain 85% of the variance. Instead of using an integer in the n_components argument to designate the number of components, we use a decimal value to indicate the amount of variance to be explained. PCA() will then automatically use enough principal components to meet this level of explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d1fcb7-1c3e-45d7-8230-8ef933ed501d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define PCA to address 85% of the variance\n",
    "pca85 = PCA(n_components=.85)\n",
    "# fit and transform on training data\n",
    "X_train_pca85 = pca85.fit_transform(X_train_sm)\n",
    "# transform test data\n",
    "X_test_pca85 = pca85.transform(X_test_tf)\n",
    "# obtain the number of PCs used\n",
    "pca85.n_components_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e9dbeb-a30f-4b12-ba68-44254d9203ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record the start time\n",
    "start = dt.datetime.now()\n",
    "\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_train_pca85, y_train_sm)\n",
    "\n",
    "# Record the end time and calc duration\n",
    "end = dt.datetime.now()\n",
    "dur_pca_85 = end-start\n",
    "\n",
    "evaluate_classification(clf, X_train_pca85,y_train_sm, X_test_pca85, y_test)\n",
    "print(f'Training time was: {dur_pca_85}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5ff3b1-5119-416c-b749-cd50952aed80",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_speed = dur_baseline/dur_pca_85\n",
    "print(f\"Using PC's with .85 was {compare_speed:.2f} times faster!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72c7fb4-2175-485e-892a-0b5cbd1dcd66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4aa044fd-ecf2-49d8-b123-8b7ac42c267d",
   "metadata": {},
   "source": [
    "# Feature Engineering: Overloaded Operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6516beb5-48ea-49d0-96a3-8d2765a7a098",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vReZBM5OC6GLYbacisp_ToNiu3CLWxqPXw7mWBsdRjnYOFLWNufdQ4qd8u5qTzUF2_sBUAMEi5cgy1U/pub?gid=1040198428&single=true&output=csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267fcad8-7e4b-4fe7-b165-58862839ba2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summing Features:\n",
    "df['TotalFamily'] = df['SibSp'] + df['Parch'] \n",
    "df = df.drop(['SibSp', 'Parch'], axis=1)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f2fb86-71c7-4a1a-a7be-dd582640e821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating Features:\n",
    "\n",
    "df['Age'] = df['Age'].round(-1)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08e7203-869b-486b-84f7-b3898d00870a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GenderAge'] = df['Sex'] + df['Age'].astype('string')\n",
    "df.drop(columns=['Sex','Age'], inplace=True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd9654e-b0c8-4870-b13f-e1755605d042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Squaring and Multiplying Features\n",
    "\n",
    "df['NormedFare'] = df['Fare'] * df['Pclass']**2\n",
    "df.drop(columns='Fare', inplace=True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe87a25-fe91-4647-9612-972760874cfa",
   "metadata": {},
   "source": [
    "# Feature Engineering: Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b57083-7854-4893-b92b-f2f0df421ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vReZBM5OC6GLYbacisp_ToNiu3CLWxqPXw7mWBsdRjnYOFLWNufdQ4qd8u5qTzUF2_sBUAMEi5cgy1U/pub?gid=1040198428&single=true&output=csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34034b8b-67e0-4852-9ede-4e0eb4cb864f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating Features: Strings\n",
    "\n",
    "# create 2 new columns, FirstName and LastName by splitting the Name column\n",
    "df[['LastName','FirstName']] = df['Name'].str.split(',', expand=True)\n",
    "# drop the 'Name' column\n",
    "df.drop('Name', axis=1, inplace=True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c92f50-7577-45cf-baf8-a32550ce3e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean-up\n",
    "\n",
    "df.loc[0,'FirstName']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211fad1f-729e-46b9-9ce3-b9e17b4491e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FirstName'] = df['FirstName'].str.strip()\n",
    "df.loc[0, 'FirstName']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd39bbd9-309f-4fc1-b063-065b84008f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining Strings\n",
    "\n",
    "df['Name'] = df['FirstName'] + ' ' + df['LastName']\n",
    "df.drop(columns=['LastName','FirstName'], inplace= True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8282ecf-450e-4cad-b1fc-6df559e9a0ef",
   "metadata": {},
   "source": [
    "# Feature Engineering: Datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40012c6f-e74e-4a19-9224-9d1bd14ae7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df2 = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vSrgrUnz8mdosU-_k0aECouymqwds_mlaHpYlXzRtf7MBJ4N1r1inCfSDebaXwTVfLtH133EhwKf3mi/pub?gid=394699239&single=true&output=csv',                  usecols=['date','price','bedrooms','bathrooms'])\n",
    "df2.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6591632-e15f-4946-bba6-3c0666288246",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['date'] = pd.to_datetime(df2['date'])\n",
    "df2.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8590db5d-eaa6-4f1d-826c-e4f33d330e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['year'] = df2['date'].dt.year\n",
    "df2['month (numeric)'] = df2['date'].dt.month\n",
    "df2['month (name)'] = df2['date'].dt.month_name()\n",
    "df2['day of month'] = df2['date'].dt.day\n",
    "df2['day of week (numeric)'] = df2['date'].dt.weekday\n",
    "df2['day of week (name)'] = df2['date'].dt.day_name()\n",
    "df2.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd76a4d0-a8c9-4f71-a328-16fb545445f0",
   "metadata": {},
   "source": [
    "# Feature Engineering: Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ce585f-d8d4-4ddb-a61e-ca66046935f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vReZBM5OC6GLYbacisp_ToNiu3CLWxqPXw7mWBsdRjnYOFLWNufdQ4qd8u5qTzUF2_sBUAMEi5cgy1U/pub?gid=1040198428&single=true&output=csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d414ac08-0233-46c8-b65f-25494ebd4981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the median fare price\n",
    "median_fare = df['Fare'].median()\n",
    "# define a function that returns 'Expensive' or 'Cheap'\n",
    "def bin_fare(fare):\n",
    "    if fare > median_fare:    \n",
    "        return 'Expensive'  \n",
    "    else:    \n",
    "        return 'Cheap'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d1f1f6-28df-4623-826a-e100bc1c5de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply bin_fare() function to each item in the 'Fare' column\n",
    "df['Fare'] = df['Fare'].apply(bin_fare)\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4707df-d5f2-4f4e-a868-41ae45915d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age'] = df['Age'].apply(lambda x: 'elderly' if x > 30 else 'young')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f89bb76-37fa-4601-8755-3c7bc765f992",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f8570c-5d56-4b25-b31b-2e744e66eb89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
